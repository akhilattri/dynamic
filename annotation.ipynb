{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "nX9OpblqWuXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "NQVtAMQBAr2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLpF3BzMWrEs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB,CategoricalNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/PROJECT_DIR/data/arc.csv\""
      ],
      "metadata": {
        "id": "yIBCwvBpAoS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path2=\"/content/drive/MyDrive/PROJECT_DIR/data/ant-1.7.csv\""
      ],
      "metadata": {
        "id": "-mrPfBdsqM4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = [file for file in os.listdir('/content/drive/MyDrive/PROJECT_DIR/data/') if file.endswith('.csv')]\n",
        "dfs = {}  # Dictionary to store dataframes\n",
        "\n",
        "for file in csv_files:\n",
        "    df_name = file.split('.')[0]  # Extract dataframe name from file name\n",
        "    file_path = '/content/drive/MyDrive/PROJECT_DIR/data/' + file\n",
        "    dfs[df_name] = pd.read_csv(file_path)\n",
        "\n",
        "# ######## print check ########\n",
        "# for df_name, df in dfs.items():\n",
        "#     print(f\"DataFrame: {df_name}\")\n",
        "#     print(df.head())  # Display first few rows of each dataframe"
      ],
      "metadata": {
        "id": "hVdbuWXO_wFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data path: /content/drive/MyDrive/PROJECT_DIR/data/arc.csv"
      ],
      "metadata": {
        "id": "ds7fWOcnAq1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(path2)\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "gvpy1qn2A1ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_2=pd.read_csv(path2)"
      ],
      "metadata": {
        "id": "rEzuYFFnp_TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('bug', axis=1)  # Features\n",
        "y = data['bug']  # Target variable"
      ],
      "metadata": {
        "id": "W1CkKl4xBS4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# scaler = MinMaxScaler()\n",
        "# scaled_data = scaler.fit_transform(X)\n",
        "# X = pd.DataFrame(scaled_data,\n",
        "# \t\t\t\t\t\tcolumns=X.columns)\n",
        "# X.head()\n"
      ],
      "metadata": {
        "id": "MYWZUS2vwDz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_log= pd.get_dummies(data['bug'], prefix='binary')\n",
        "# y_log.head()"
      ],
      "metadata": {
        "id": "wnSy7Jbgrlfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runMLP():\n",
        "    MLP = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
        "    MLP.fit(x_train, y_train)\n",
        "    y_pred = MLP.predict(x_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    # print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "0zkzznwdUiRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runNB():\n",
        "    gnb=GaussianNB()\n",
        "    cnb=CategoricalNB()\n",
        "\n",
        "    gnb.fit(x_train,y_train)\n",
        "    cnb.fit(x_train,y_train)\n",
        "\n",
        "    y_gnb_pred=gnb.predict(x_test)\n",
        "    # y_cnb_pred=cnb.predict(x_test)\n",
        "\n",
        "    print(classification_report(y_test, y_gnb_pred))\n",
        "    # print(classification_report(y_test, y_cnb_pred))"
      ],
      "metadata": {
        "id": "wrNzj_vkUizR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runRBF():\n",
        "    rbf = SVC(kernel='rbf', random_state=423843)\n",
        "\n",
        "    rbf.fit(x_train,y_train)\n",
        "\n",
        "    y_rbf_pred=rbf.predict(x_test)\n",
        "\n",
        "    print(classification_report(y_test, y_rbf_pred))"
      ],
      "metadata": {
        "id": "b8jVqIoiUkls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runLOG():\n",
        "    lgr=LogisticRegression(random_state=0)\n",
        "\n",
        "    lgr.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "oz7jj1LBUnHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def runDTree():\n",
        "    dtree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "    dtree.fit(x_train, y_train)\n",
        "\n",
        "    y_pred = dtree.predict(x_test)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "GJFAx6kog8nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def runVoting():\n",
        "    gnb = GaussianNB()\n",
        "    cnb = CategoricalNB()\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
        "\n",
        "    estimators = [('gnb', gnb), ('cnb', cnb), ('mlp', mlp)]\n",
        "    voting_clf = VotingClassifier(estimators=estimators, voting='hard')\n",
        "\n",
        "    voting_clf.fit(x_train, y_train)\n",
        "\n",
        "    y_pred = voting_clf.predict(x_test)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "runVoting()"
      ],
      "metadata": {
        "id": "KN6SUowqhO_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df_name, df in dfs.items():\n",
        "    # Perform operations on df or df_name\n",
        "    print(f\"DataFrame Name: {df_name}\")\n",
        "    print(df.head())  # Example operation: Display first few rows of each dataframe\n",
        "\n",
        "    x = df.drop('bug', axis=1)  # Features\n",
        "    y = df['bug']  # Target variable\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    runMLP()\n",
        "    runNB()\n",
        "    runRBF()\n",
        "    runLOG()\n",
        "    runDTree()\n",
        "    runVoting()"
      ],
      "metadata": {
        "id": "_IcpzqAPUp1E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}